{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "PROJECT_DIR = \"/Users/raghav/envPython3/experiments/one_class_neural_networks/\"\n",
    "import sys,os\n",
    "import numpy as np\n",
    "sys.path.append(PROJECT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain Training and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCAE.RESULT_PATH: /Users/raghav/envPython3/experiments/one_class_neural_networks//reports/figures/MNIST/RCAE/\n",
      "Inside the MNIST_DataLoader RCAE.RESULT_PATH: ../reports/figures/MNIST/RCAE/\n",
      "[INFO: ] Loading data...\n",
      "[INFO] : The shape of X is:  (60000, 28, 28, 1)\n",
      "[INFO] : The shape of y is:  (60000,)\n",
      "[INFO:] The shape of Normal used in training+validation  (4936, 28, 28, 1)\n",
      "[INFO:] The shape of Outlier used in training+validation  (50, 28, 28, 1)\n",
      "[INFO] : The shape of X is:  (10000, 28, 28, 1)\n",
      "[INFO] : The shape of y is:  (10000,)\n",
      "[INFO:] The shape of  Normal instances used in Testing  (980, 28, 28, 1)\n",
      "[INFO:] The shape of  Outlier instances used in Testing  (9020, 28, 28, 1)\n",
      "========================================================================\n",
      "[INFO: ] Data loaded.\n",
      "Inside the MNIST_DataLoader RCAE.RESULT_PATH: ../reports/figures/MNIST/RCAE/\n",
      "[INFO: ] Loading data...\n",
      "[INFO] : The shape of X is:  (60000, 28, 28, 1)\n",
      "[INFO] : The shape of y is:  (60000,)\n",
      "[INFO:] The shape of Normal used in training+validation  (4936, 28, 28, 1)\n",
      "[INFO:] The shape of Outlier used in training+validation  (50, 28, 28, 1)\n",
      "[INFO] : The shape of X is:  (10000, 28, 28, 1)\n",
      "[INFO] : The shape of y is:  (10000,)\n",
      "[INFO:] The shape of  Normal instances used in Testing  (980, 28, 28, 1)\n",
      "[INFO:] The shape of  Outlier instances used in Testing  (9020, 28, 28, 1)\n",
      "========================================================================\n",
      "[INFO: ] Data loaded.\n",
      "Train Data Shape:  (4986, 28, 28, 1)\n",
      "Train Label Shape:  (4986,)\n",
      "Validation Data Shape:  (997, 28, 28, 1)\n",
      "Validation Label Shape:  (997,)\n",
      "Test Data Shape:  (10000, 28, 28, 1)\n",
      "Test Label Shape:  (10000,)\n",
      "===========TRAINING AND PREDICTING WITH RCAE============================\n",
      "[INFO:]  Length of Positive data 5920\n",
      "[INFO:]  Length of Negative data 63\n",
      "[INFO:] X_test.shape (5983, 28, 28, 1)\n",
      "[INFO:] y_test.shape [ 1.  1.  1. ... -1. -1. -1.]\n",
      "[INFO:] y_train.shape (5983,)\n",
      "[INFO:] y_train.shape [ 1.  1.  1. ... -1. -1. -1.]\n",
      "[INFO] compiling model...\n",
      "Train on 5384 samples, validate on 599 samples\n",
      "Epoch 1/350\n",
      "5384/5384 [==============================] - 43s 8ms/step - loss: 5.0908 - val_loss: 5.0175\n",
      "Epoch 2/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9809 - val_loss: 4.9766\n",
      "Epoch 3/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9698 - val_loss: 4.9724\n",
      "Epoch 4/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9665 - val_loss: 4.9696\n",
      "Epoch 5/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 4.9644 - val_loss: 4.9682\n",
      "Epoch 6/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9630 - val_loss: 4.9667\n",
      "Epoch 7/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9619 - val_loss: 4.9651\n",
      "Epoch 8/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9611 - val_loss: 4.9645\n",
      "Epoch 9/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9604 - val_loss: 4.9634\n",
      "Epoch 10/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9599 - val_loss: 4.9627\n",
      "Epoch 11/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9594 - val_loss: 4.9622\n",
      "Epoch 12/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9591 - val_loss: 4.9616\n",
      "Epoch 13/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9587 - val_loss: 4.9612\n",
      "Epoch 14/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 4.9585 - val_loss: 4.9610\n",
      "Epoch 15/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9582 - val_loss: 4.9606\n",
      "Epoch 16/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9580 - val_loss: 4.9604\n",
      "Epoch 17/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9578 - val_loss: 4.9600\n",
      "Epoch 18/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9577 - val_loss: 4.9598\n",
      "Epoch 19/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9575 - val_loss: 4.9597\n",
      "Epoch 20/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9573 - val_loss: 4.9594\n",
      "Epoch 21/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9572 - val_loss: 4.9592\n",
      "Epoch 22/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9571 - val_loss: 4.9591\n",
      "Epoch 23/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9569 - val_loss: 4.9589\n",
      "Epoch 24/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9569 - val_loss: 4.9588\n",
      "Epoch 25/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9567 - val_loss: 4.9587\n",
      "Epoch 26/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9566 - val_loss: 4.9586\n",
      "Epoch 27/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9565 - val_loss: 4.9585\n",
      "Epoch 28/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9565 - val_loss: 4.9584\n",
      "Epoch 29/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9564 - val_loss: 4.9583\n",
      "Epoch 30/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9563 - val_loss: 4.9582\n",
      "Epoch 31/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9563 - val_loss: 4.9581\n",
      "Epoch 32/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9562 - val_loss: 4.9581\n",
      "Epoch 33/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9561 - val_loss: 4.9580\n",
      "Epoch 34/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9561 - val_loss: 4.9579\n",
      "Epoch 35/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9560 - val_loss: 4.9578\n",
      "Epoch 36/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9559 - val_loss: 4.9577\n",
      "Epoch 37/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9559 - val_loss: 4.9577\n",
      "Epoch 38/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9558 - val_loss: 4.9576\n",
      "Epoch 39/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9557 - val_loss: 4.9575\n",
      "Epoch 40/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9557 - val_loss: 4.9575\n",
      "Epoch 41/350\n",
      "5384/5384 [==============================] - 29s 5ms/step - loss: 4.9556 - val_loss: 4.9574\n",
      "Epoch 42/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9556 - val_loss: 4.9575\n",
      "Epoch 43/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9556 - val_loss: 4.9574\n",
      "Epoch 44/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9555 - val_loss: 4.9573\n",
      "Epoch 45/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9555 - val_loss: 4.9573\n",
      "Epoch 46/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9555 - val_loss: 4.9573\n",
      "Epoch 47/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9554 - val_loss: 4.9571\n",
      "Epoch 48/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9554 - val_loss: 4.9571\n",
      "Epoch 49/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9554 - val_loss: 4.9571\n",
      "Epoch 50/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9553 - val_loss: 4.9570\n",
      "Epoch 51/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9553 - val_loss: 4.9570\n",
      "Epoch 52/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9552 - val_loss: 4.9570\n",
      "Epoch 53/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9552 - val_loss: 4.9569\n",
      "Epoch 54/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9552 - val_loss: 4.9569\n",
      "Epoch 55/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9551 - val_loss: 4.9569\n",
      "Epoch 56/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9551 - val_loss: 4.9568\n",
      "Epoch 57/350\n",
      "5384/5384 [==============================] - 3315s 616ms/step - loss: 4.9551 - val_loss: 4.9568\n",
      "Epoch 58/350\n",
      "5384/5384 [==============================] - 491s 91ms/step - loss: 4.9551 - val_loss: 4.9568\n",
      "Epoch 59/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 27s 5ms/step - loss: 4.9550 - val_loss: 4.9567\n",
      "Epoch 60/350\n",
      "5384/5384 [==============================] - 28s 5ms/step - loss: 4.9550 - val_loss: 4.9567\n",
      "Epoch 61/350\n",
      "5384/5384 [==============================] - 29s 5ms/step - loss: 4.9550 - val_loss: 4.9567\n",
      "Epoch 62/350\n",
      "5384/5384 [==============================] - 28s 5ms/step - loss: 4.9549 - val_loss: 4.9567\n",
      "Epoch 63/350\n",
      "5384/5384 [==============================] - 28s 5ms/step - loss: 4.9549 - val_loss: 4.9566\n",
      "Epoch 64/350\n",
      "5384/5384 [==============================] - 28s 5ms/step - loss: 4.9549 - val_loss: 4.9566\n",
      "Epoch 65/350\n",
      "5384/5384 [==============================] - 29s 5ms/step - loss: 4.9549 - val_loss: 4.9566\n",
      "Epoch 66/350\n",
      "5384/5384 [==============================] - 29s 5ms/step - loss: 4.9548 - val_loss: 4.9566\n",
      "Epoch 67/350\n",
      "5384/5384 [==============================] - 29s 5ms/step - loss: 4.9549 - val_loss: 4.9565\n",
      "Epoch 68/350\n",
      "5384/5384 [==============================] - 29s 5ms/step - loss: 4.9548 - val_loss: 4.9565\n",
      "Epoch 69/350\n",
      "5384/5384 [==============================] - 29s 5ms/step - loss: 4.9547 - val_loss: 4.9565\n",
      "Epoch 70/350\n",
      "5384/5384 [==============================] - 29s 5ms/step - loss: 4.9548 - val_loss: 4.9564\n",
      "Epoch 71/350\n",
      "5384/5384 [==============================] - 29s 5ms/step - loss: 4.9547 - val_loss: 4.9564\n",
      "Epoch 72/350\n",
      "5384/5384 [==============================] - 29s 5ms/step - loss: 4.9547 - val_loss: 4.9564\n",
      "Epoch 73/350\n",
      "5384/5384 [==============================] - 29s 5ms/step - loss: 4.9547 - val_loss: 4.9564\n",
      "Epoch 74/350\n",
      "5384/5384 [==============================] - 30s 5ms/step - loss: 4.9547 - val_loss: 4.9563\n",
      "Epoch 75/350\n",
      "5384/5384 [==============================] - 30s 5ms/step - loss: 4.9546 - val_loss: 4.9563\n",
      "Epoch 76/350\n",
      "5384/5384 [==============================] - 30s 5ms/step - loss: 4.9546 - val_loss: 4.9563\n",
      "Epoch 77/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9546 - val_loss: 4.9563\n",
      "Epoch 78/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9545 - val_loss: 4.9563\n",
      "Epoch 79/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9546 - val_loss: 4.9562\n",
      "Epoch 80/350\n",
      "5384/5384 [==============================] - 30s 5ms/step - loss: 4.9545 - val_loss: 4.9562\n",
      "Epoch 81/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9546 - val_loss: 4.9562\n",
      "Epoch 82/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9546 - val_loss: 4.9562\n",
      "Epoch 83/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9545 - val_loss: 4.9562\n",
      "Epoch 84/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9545 - val_loss: 4.9562\n",
      "Epoch 85/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9545 - val_loss: 4.9561\n",
      "Epoch 86/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9545 - val_loss: 4.9561\n",
      "Epoch 87/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9545 - val_loss: 4.9561\n",
      "Epoch 88/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9544 - val_loss: 4.9561\n",
      "Epoch 89/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9544 - val_loss: 4.9560\n",
      "Epoch 90/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9544 - val_loss: 4.9560\n",
      "Epoch 91/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9544 - val_loss: 4.9560\n",
      "Epoch 92/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9544 - val_loss: 4.9560\n",
      "Epoch 93/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9544 - val_loss: 4.9560\n",
      "Epoch 94/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9543 - val_loss: 4.9559\n",
      "Epoch 95/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9543 - val_loss: 4.9559\n",
      "Epoch 96/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9543 - val_loss: 4.9560\n",
      "Epoch 97/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9543 - val_loss: 4.9559\n",
      "Epoch 98/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9543 - val_loss: 4.9559\n",
      "Epoch 99/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9543 - val_loss: 4.9559\n",
      "Epoch 100/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9543 - val_loss: 4.9559\n",
      "Epoch 101/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9543 - val_loss: 4.9559\n",
      "Epoch 102/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9542 - val_loss: 4.9558\n",
      "Epoch 103/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9542 - val_loss: 4.9558\n",
      "Epoch 104/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9542 - val_loss: 4.9558\n",
      "Epoch 105/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9542 - val_loss: 4.9558\n",
      "Epoch 106/350\n",
      "5384/5384 [==============================] - 30s 5ms/step - loss: 4.9542 - val_loss: 4.9558\n",
      "Epoch 107/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9542 - val_loss: 4.9558\n",
      "Epoch 108/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9542 - val_loss: 4.9558\n",
      "Epoch 109/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9541 - val_loss: 4.9558\n",
      "Epoch 110/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9542 - val_loss: 4.9558\n",
      "Epoch 111/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9541 - val_loss: 4.9557\n",
      "Epoch 112/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9541 - val_loss: 4.9557\n",
      "Epoch 113/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9541 - val_loss: 4.9557\n",
      "Epoch 114/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9541 - val_loss: 4.9557\n",
      "Epoch 115/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9541 - val_loss: 4.9557\n",
      "Epoch 116/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9541 - val_loss: 4.9557\n",
      "Epoch 117/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9541 - val_loss: 4.9557\n",
      "Epoch 118/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9541 - val_loss: 4.9556\n",
      "Epoch 119/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9541 - val_loss: 4.9556\n",
      "Epoch 120/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9540 - val_loss: 4.9556\n",
      "Epoch 121/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9540 - val_loss: 4.9556\n",
      "Epoch 122/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9540 - val_loss: 4.9556\n",
      "Epoch 123/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9540 - val_loss: 4.9556\n",
      "Epoch 124/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9540 - val_loss: 4.9556\n",
      "Epoch 125/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9540 - val_loss: 4.9556\n",
      "Epoch 126/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9540 - val_loss: 4.9556\n",
      "Epoch 127/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9540 - val_loss: 4.9555\n",
      "Epoch 128/350\n",
      "5384/5384 [==============================] - 30s 5ms/step - loss: 4.9540 - val_loss: 4.9555\n",
      "Epoch 129/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9540 - val_loss: 4.9555\n",
      "Epoch 130/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9540 - val_loss: 4.9555\n",
      "Epoch 131/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9539 - val_loss: 4.9555\n",
      "Epoch 132/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9539 - val_loss: 4.9555\n",
      "Epoch 133/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9539 - val_loss: 4.9555\n",
      "Epoch 134/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9539 - val_loss: 4.9555\n",
      "Epoch 135/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9539 - val_loss: 4.9555\n",
      "Epoch 136/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9539 - val_loss: 4.9555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9539 - val_loss: 4.9554\n",
      "Epoch 138/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9539 - val_loss: 4.9554\n",
      "Epoch 139/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9539 - val_loss: 4.9554\n",
      "Epoch 140/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9539 - val_loss: 4.9554\n",
      "Epoch 141/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9539 - val_loss: 4.9554\n",
      "Epoch 142/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9539 - val_loss: 4.9554\n",
      "Epoch 143/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9538 - val_loss: 4.9554\n",
      "Epoch 144/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9538 - val_loss: 4.9554\n",
      "Epoch 145/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9538 - val_loss: 4.9554\n",
      "Epoch 146/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9538 - val_loss: 4.9554\n",
      "Epoch 147/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9538 - val_loss: 4.9554\n",
      "Epoch 148/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9538 - val_loss: 4.9554\n",
      "Epoch 149/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9538 - val_loss: 4.9553\n",
      "Epoch 150/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9538 - val_loss: 4.9553\n",
      "Epoch 151/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9538 - val_loss: 4.9553\n",
      "Epoch 152/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9538 - val_loss: 4.9553\n",
      "Epoch 153/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9538 - val_loss: 4.9553\n",
      "Epoch 154/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9538 - val_loss: 4.9553\n",
      "Epoch 155/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9538 - val_loss: 4.9553\n",
      "Epoch 156/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9537 - val_loss: 4.9553\n",
      "Epoch 157/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9538 - val_loss: 4.9553\n",
      "Epoch 158/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9537 - val_loss: 4.9553\n",
      "Epoch 159/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9537 - val_loss: 4.9553\n",
      "Epoch 160/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9537 - val_loss: 4.9553\n",
      "Epoch 161/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9537 - val_loss: 4.9552\n",
      "Epoch 162/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9537 - val_loss: 4.9552\n",
      "Epoch 163/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9537 - val_loss: 4.9552\n",
      "Epoch 164/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9537 - val_loss: 4.9552\n",
      "Epoch 165/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9537 - val_loss: 4.9552\n",
      "Epoch 166/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9536 - val_loss: 4.9552\n",
      "Epoch 167/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9537 - val_loss: 4.9552\n",
      "Epoch 168/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9537 - val_loss: 4.9552\n",
      "Epoch 169/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9537 - val_loss: 4.9552\n",
      "Epoch 170/350\n",
      "5384/5384 [==============================] - 29s 5ms/step - loss: 4.9537 - val_loss: 4.9552\n",
      "Epoch 171/350\n",
      "5384/5384 [==============================] - 30s 5ms/step - loss: 4.9536 - val_loss: 4.9552\n",
      "Epoch 172/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9537 - val_loss: 4.9552\n",
      "Epoch 173/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9537 - val_loss: 4.9552\n",
      "Epoch 174/350\n",
      "5384/5384 [==============================] - 30s 5ms/step - loss: 4.9536 - val_loss: 4.9552\n",
      "Epoch 175/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9536 - val_loss: 4.9551\n",
      "Epoch 176/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9536 - val_loss: 4.9551\n",
      "Epoch 177/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9536 - val_loss: 4.9551\n",
      "Epoch 178/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9536 - val_loss: 4.9551\n",
      "Epoch 179/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9536 - val_loss: 4.9551\n",
      "Epoch 180/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9536 - val_loss: 4.9551\n",
      "Epoch 181/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9536 - val_loss: 4.9551\n",
      "Epoch 182/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9536 - val_loss: 4.9551\n",
      "Epoch 183/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9536 - val_loss: 4.9551\n",
      "Epoch 184/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9535 - val_loss: 4.9551\n",
      "Epoch 185/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9536 - val_loss: 4.9551\n",
      "Epoch 186/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9536 - val_loss: 4.9551\n",
      "Epoch 187/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9535 - val_loss: 4.9551\n",
      "Epoch 188/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9536 - val_loss: 4.9551\n",
      "Epoch 189/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9536 - val_loss: 4.9551\n",
      "Epoch 190/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9535 - val_loss: 4.9551\n",
      "Epoch 191/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 192/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 193/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9536 - val_loss: 4.9550\n",
      "Epoch 194/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 195/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 196/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 197/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 198/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 199/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 200/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 201/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 202/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 203/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 204/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 205/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9550\n",
      "Epoch 206/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 207/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 208/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 209/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9550\n",
      "Epoch 210/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9535 - val_loss: 4.9550\n",
      "Epoch 211/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 212/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 213/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 214/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 215/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 216/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 217/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 218/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 219/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 220/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 221/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 222/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 223/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 224/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 225/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 226/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 227/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9533 - val_loss: 4.9549\n",
      "Epoch 228/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 229/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 230/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9534 - val_loss: 4.9549\n",
      "Epoch 231/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9549\n",
      "Epoch 232/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9533 - val_loss: 4.9549\n",
      "Epoch 233/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 234/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9534 - val_loss: 4.9548\n",
      "Epoch 235/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9534 - val_loss: 4.9548\n",
      "Epoch 236/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9534 - val_loss: 4.9548\n",
      "Epoch 237/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 238/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 239/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 240/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 241/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 242/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 243/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 244/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 245/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 246/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 247/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 248/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 249/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 250/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 251/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 252/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 253/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 254/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 255/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 256/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 257/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9533 - val_loss: 4.9548\n",
      "Epoch 258/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9533 - val_loss: 4.9547\n",
      "Epoch 259/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 260/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 261/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 262/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 263/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 264/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9533 - val_loss: 4.9547\n",
      "Epoch 265/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 266/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 267/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 268/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 269/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 270/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 271/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 272/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 273/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 274/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 275/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 276/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 277/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 278/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 279/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 280/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 281/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 282/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9532 - val_loss: 4.9546\n",
      "Epoch 283/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 284/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9532 - val_loss: 4.9547\n",
      "Epoch 285/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9532 - val_loss: 4.9546\n",
      "Epoch 286/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9532 - val_loss: 4.9546\n",
      "Epoch 287/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 288/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9546\n",
      "Epoch 289/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 290/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9532 - val_loss: 4.9546\n",
      "Epoch 291/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 292/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 293/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 294/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9532 - val_loss: 4.9546\n",
      "Epoch 295/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 296/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 297/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 298/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 299/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 300/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 301/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 302/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9532 - val_loss: 4.9546\n",
      "Epoch 303/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 304/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 305/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 306/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 307/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 308/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 309/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 310/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 311/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 312/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 313/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 314/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 315/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9531 - val_loss: 4.9546\n",
      "Epoch 316/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9531 - val_loss: 4.9545\n",
      "Epoch 317/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9531 - val_loss: 4.9545\n",
      "Epoch 318/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9531 - val_loss: 4.9545\n",
      "Epoch 319/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9531 - val_loss: 4.9545\n",
      "Epoch 320/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9531 - val_loss: 4.9545\n",
      "Epoch 321/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9531 - val_loss: 4.9545\n",
      "Epoch 322/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9531 - val_loss: 4.9545\n",
      "Epoch 323/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9531 - val_loss: 4.9545\n",
      "Epoch 324/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 325/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9531 - val_loss: 4.9545\n",
      "Epoch 326/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 327/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 328/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 329/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 330/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 331/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 332/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 333/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 334/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 335/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 336/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 337/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 338/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 339/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 340/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 341/350\n",
      "5384/5384 [==============================] - 41s 8ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 342/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 343/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 344/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 345/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 346/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 347/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 348/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 349/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "Epoch 350/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9530 - val_loss: 4.9545\n",
      "(lamda,Threshold) 0.0 0.0\n",
      "The type of b is ..., its len is  <class 'numpy.ndarray'> (5983, 784) 784\n",
      "Iteration NUmber is :  0\n",
      "NUmber of non zero elements  for N,lamda 4690672 0.0\n",
      "The shape of N (5983, 784)\n",
      "The minimum value of N  -0.81482404\n",
      "The max value of N 0.9902173\n",
      "[INFO:] Xclean  MSE Computed shape (5983, 784)\n",
      "[INFO:]Xdecoded  Computed shape (5983, 784)\n",
      "[INFO:] MSE Computed shape ()\n",
      "\n",
      " Mean square error Score ((Xclean, Xdecoded):\n",
      "dict_values([0.0038226442])\n",
      "[INFO:] The anomaly threshold computed is  0.0038226442\n",
      "side: 28\n",
      "channel: 1\n",
      "\n",
      "Saving results for best after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//best/\n",
      "\n",
      "Saving results for worst after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//worst/\n",
      "[INFO:] The anomaly index are  [5944, 5982, 5968, 5925, 5930, 5943, 5972, 5939, 5979, 5945, 5922, 5966, 5953, 5977, 5934, 5978, 5963, 5926, 5928, 5929, 5921, 5948, 5960, 5952, 5959, 5955, 5924, 5965, 5967, 5958, 5974, 5956, 5927, 5931, 5940, 5936, 5981, 5950, 5957, 5946, 5920, 5975, 5923, 5942, 5941, 5961, 5947, 5970, 5962, 5980, 5933, 5973, 5951, 5976, 5935, 5964, 5938, 2977, 5949, 5971, 2749, 2683, 4541]\n",
      "=====================\n",
      "AUROC 0.0 0.9603174603174603\n",
      "=======================\n",
      "[INFO] compiling model...\n",
      "Train on 5384 samples, validate on 599 samples\n",
      "Epoch 1/350\n",
      "5384/5384 [==============================] - 44s 8ms/step - loss: 4.9530 - val_loss: 4.9544\n",
      "Epoch 2/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9530 - val_loss: 4.9544\n",
      "Epoch 3/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9530 - val_loss: 4.9544\n",
      "Epoch 4/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 5/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9530 - val_loss: 4.9544\n",
      "Epoch 6/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9530 - val_loss: 4.9544\n",
      "Epoch 7/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9530 - val_loss: 4.9544\n",
      "Epoch 8/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 9/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 4.9530 - val_loss: 4.9544\n",
      "Epoch 10/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9530 - val_loss: 4.9544\n",
      "Epoch 11/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 4.9530 - val_loss: 4.9544\n",
      "Epoch 12/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 13/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 14/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9530 - val_loss: 4.9544\n",
      "Epoch 15/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 16/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 17/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9530 - val_loss: 4.9544\n",
      "Epoch 18/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 19/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 20/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 21/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 22/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 23/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 24/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 25/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 26/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 27/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 28/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 29/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9529 - val_loss: 4.9544\n",
      "Epoch 30/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 31/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 32/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 33/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 34/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 35/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 36/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 37/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 38/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 39/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 40/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 41/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 42/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 43/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 44/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 45/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 46/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 47/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 48/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 49/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 50/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 51/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 52/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 53/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 54/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 55/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 56/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9529 - val_loss: 4.9543\n",
      "Epoch 57/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 58/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 59/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 60/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 61/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9528 - val_loss: 4.9543\n",
      "Epoch 62/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 63/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 64/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 65/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 66/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 67/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 68/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 69/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 70/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 71/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 72/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 73/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 74/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 75/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 76/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 77/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 78/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 79/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 80/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 81/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 82/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 83/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 84/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 85/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 86/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 87/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 88/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 89/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 90/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 91/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 92/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 93/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 94/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 95/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 96/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 97/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 98/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 99/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 100/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9542\n",
      "Epoch 101/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 102/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 103/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 104/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 105/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9542\n",
      "Epoch 106/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 107/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 108/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9528 - val_loss: 4.9541\n",
      "Epoch 109/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 110/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 111/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 112/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 113/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 114/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 115/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 116/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 117/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 118/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 119/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 120/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 121/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 122/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 123/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 124/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9541\n",
      "Epoch 125/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 126/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 127/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 128/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 129/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 130/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 131/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 132/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 133/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 134/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9541\n",
      "Epoch 135/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 136/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9541\n",
      "Epoch 137/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9541\n",
      "Epoch 138/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 139/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 140/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 141/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9541\n",
      "Epoch 142/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 143/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 144/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9541\n",
      "Epoch 145/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 146/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9541\n",
      "Epoch 147/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 148/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 149/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 150/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9541\n",
      "Epoch 151/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 152/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9527 - val_loss: 4.9541\n",
      "Epoch 153/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9541\n",
      "Epoch 154/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 155/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9541\n",
      "Epoch 156/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 157/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9541\n",
      "Epoch 158/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 159/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 160/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 161/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 162/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 163/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 164/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 165/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 166/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 167/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 168/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 169/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 170/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 171/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 172/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 173/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 174/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 175/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 176/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 177/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 178/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 179/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 180/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 181/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 182/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 183/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 184/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 185/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 186/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 187/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 188/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 189/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 190/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 191/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 192/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 193/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 194/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 195/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 196/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 197/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 198/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 199/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 200/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 201/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 202/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 203/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9540\n",
      "Epoch 204/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 205/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9540\n",
      "Epoch 206/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 207/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9540\n",
      "Epoch 208/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9540\n",
      "Epoch 209/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 210/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9540\n",
      "Epoch 211/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9540\n",
      "Epoch 212/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9540\n",
      "Epoch 213/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 214/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9540\n",
      "Epoch 215/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9526 - val_loss: 4.9540\n",
      "Epoch 216/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9540\n",
      "Epoch 217/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9540\n",
      "Epoch 218/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 219/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9526 - val_loss: 4.9539\n",
      "Epoch 220/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 221/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 222/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 223/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 224/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 225/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 226/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 227/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 228/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9540\n",
      "Epoch 229/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 230/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 231/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 232/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 233/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 234/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 235/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 236/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 237/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 238/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 239/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 240/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 241/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 242/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 243/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 244/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 245/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 246/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 247/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 248/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 249/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 250/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 251/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 252/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 253/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 254/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 255/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 256/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 257/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 258/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 259/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 260/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 261/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 262/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 263/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 264/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 265/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 266/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 267/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 268/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 269/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 270/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 271/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 272/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 273/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 274/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 275/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 276/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9539\n",
      "Epoch 277/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 278/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 279/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 280/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 281/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 282/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 283/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 284/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 285/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9539\n",
      "Epoch 286/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 287/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 288/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 289/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 290/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 291/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9539\n",
      "Epoch 292/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 293/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9539\n",
      "Epoch 294/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 295/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 296/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 297/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 298/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 299/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9539\n",
      "Epoch 300/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 301/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 302/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9538\n",
      "Epoch 303/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 304/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9538\n",
      "Epoch 305/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 306/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 307/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9538\n",
      "Epoch 308/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 309/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 310/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 311/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 312/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 313/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9538\n",
      "Epoch 314/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 315/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9538\n",
      "Epoch 316/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 317/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 318/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9525 - val_loss: 4.9538\n",
      "Epoch 319/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 320/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 321/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 322/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9525 - val_loss: 4.9538\n",
      "Epoch 323/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 324/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 325/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 326/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 327/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 328/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 329/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 330/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 331/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 332/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 333/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 334/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 335/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 336/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 337/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 338/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 339/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 340/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 341/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 342/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 343/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 344/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 345/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 346/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 347/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 348/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 349/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "Epoch 350/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9524 - val_loss: 4.9538\n",
      "(lamda,Threshold) 0.01 0.005\n",
      "The type of b is ..., its len is  <class 'numpy.ndarray'> (5983, 784) 784\n",
      "Iteration NUmber is :  0\n",
      "NUmber of non zero elements  for N,lamda 3938619 0.01\n",
      "The shape of N (5983, 784)\n",
      "The minimum value of N  -0.828008770942688\n",
      "The max value of N 0.9859393239021301\n",
      "[INFO:] Xclean  MSE Computed shape (5983, 784)\n",
      "[INFO:]Xdecoded  Computed shape (5983, 784)\n",
      "[INFO:] MSE Computed shape ()\n",
      "\n",
      " Mean square error Score ((Xclean, Xdecoded):\n",
      "dict_values([0.0038226442, 0.0032461267])\n",
      "[INFO:] The anomaly threshold computed is  0.0032461267\n",
      "side: 28\n",
      "channel: 1\n",
      "\n",
      "Saving results for best after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//best/\n",
      "\n",
      "Saving results for worst after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//worst/\n",
      "[INFO:] The anomaly index are  [5944, 5982, 5968, 5925, 5930, 5939, 5979, 5945, 5943, 5972, 5922, 5926, 5966, 5934, 5978, 5928, 5953, 5977, 5963, 5929, 5955, 5960, 5965, 5921, 5948, 5952, 5959, 5940, 5924, 5927, 5931, 5956, 5967, 5950, 5958, 5974, 5936, 5981, 5923, 5946, 5957, 5941, 5933, 5973, 5938, 5920, 5975, 5962, 5980, 5951, 5976, 5964, 5947, 5970, 5961, 5942, 5935, 2977, 2683, 2749, 5949, 5971, 5954]\n",
      "=====================\n",
      "AUROC 0.01 0.9682539682539683\n",
      "=======================\n",
      "[INFO] compiling model...\n",
      "Train on 5384 samples, validate on 599 samples\n",
      "Epoch 1/350\n",
      "5384/5384 [==============================] - 43s 8ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 2/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 3/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 4/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5388 - val_loss: 5.5401\n",
      "Epoch 5/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 6/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 7/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 8/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 9/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 10/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 11/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 12/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 13/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 14/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5388 - val_loss: 5.5401\n",
      "Epoch 15/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 16/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 17/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 18/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 19/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 20/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 21/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 22/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 23/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 24/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 25/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 26/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 27/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 28/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 29/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 30/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 31/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 32/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 33/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 34/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 35/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 36/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 37/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 38/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 39/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 40/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 41/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 42/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 43/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 44/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 45/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 46/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 47/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 48/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 49/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5401\n",
      "Epoch 50/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 51/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 52/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 53/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5401\n",
      "Epoch 54/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 55/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 56/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 57/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 58/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 59/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 60/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5401\n",
      "Epoch 61/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5401\n",
      "Epoch 62/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 63/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 64/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5401\n",
      "Epoch 65/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 66/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 67/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 68/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 69/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 70/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 71/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 72/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 73/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 74/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 75/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 76/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 77/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 78/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 79/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 80/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 81/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 82/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 83/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 84/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 85/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 86/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 87/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 88/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 89/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 90/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 91/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 92/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 93/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 94/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 95/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 96/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 97/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 98/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 99/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5387 - val_loss: 5.5400\n",
      "Epoch 100/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 101/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 102/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 103/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 104/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 105/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 106/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 107/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 108/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 109/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 110/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 111/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 112/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 113/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 114/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 115/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 116/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 117/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 118/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 119/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 120/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 121/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 122/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 123/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 124/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 125/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 126/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 127/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 128/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 129/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 130/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 131/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 132/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 133/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 134/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 135/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 136/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 137/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 138/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 139/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 140/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 141/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 142/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 143/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 144/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 145/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 146/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 147/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 148/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 149/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 150/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 151/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 152/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5400\n",
      "Epoch 153/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 154/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 155/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 156/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 157/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 158/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 159/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 160/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 161/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 162/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5400\n",
      "Epoch 163/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 164/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 165/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 166/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 167/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 168/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 169/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 170/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 171/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 172/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 173/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 174/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 175/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 176/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 177/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 178/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 179/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 180/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 181/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 182/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 183/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 184/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 185/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 186/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 187/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 188/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 189/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 190/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 191/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 192/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 193/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 194/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 195/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 196/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 197/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 198/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 199/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 200/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 201/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 202/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 203/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 204/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 205/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 206/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 207/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 208/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 209/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 210/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 211/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 212/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 213/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 214/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 215/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 216/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 217/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 218/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 219/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 220/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 221/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 222/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 223/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 224/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5386 - val_loss: 5.5399\n",
      "Epoch 225/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 226/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 227/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 228/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 229/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 230/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 231/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 232/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 233/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 234/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 235/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 236/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 237/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 238/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 239/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 240/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 241/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 242/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 243/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 244/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 245/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 246/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 247/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 248/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 249/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 250/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 251/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 252/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 253/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 254/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 255/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 256/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 257/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 258/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 259/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 260/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 261/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 262/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 263/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 264/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 265/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 266/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 267/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 268/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 269/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 270/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 271/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 272/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 273/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 274/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 275/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 276/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 277/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 278/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 279/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 280/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 281/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 282/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 283/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 284/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 285/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 286/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 287/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 288/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 289/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 290/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 291/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 292/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 293/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 294/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 295/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 296/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 297/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 298/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 299/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 300/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 301/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 302/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 303/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 304/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 305/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 306/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 307/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 308/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 309/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 310/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 311/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 312/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5399\n",
      "Epoch 313/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 314/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 315/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 316/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 317/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 318/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 319/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 320/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 321/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 322/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 323/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 324/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 325/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 326/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 327/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 328/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 329/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 330/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 331/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 332/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 333/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 334/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 335/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 336/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 337/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 338/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 339/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 340/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 341/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 342/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 343/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 344/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 345/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 346/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 347/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 348/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5384 - val_loss: 5.5398\n",
      "Epoch 349/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "Epoch 350/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 5.5385 - val_loss: 5.5398\n",
      "(lamda,Threshold) 0.1 0.05\n",
      "The type of b is ..., its len is  <class 'numpy.ndarray'> (5983, 784) 784\n",
      "Iteration NUmber is :  0\n",
      "NUmber of non zero elements  for N,lamda 849705 0.1\n",
      "The shape of N (5983, 784)\n",
      "The minimum value of N  -0.7856602072715759\n",
      "The max value of N 0.9413470029830933\n",
      "[INFO:] Xclean  MSE Computed shape (5983, 784)\n",
      "[INFO:]Xdecoded  Computed shape (5983, 784)\n",
      "[INFO:] MSE Computed shape ()\n",
      "\n",
      " Mean square error Score ((Xclean, Xdecoded):\n",
      "dict_values([0.0038226442, 0.0032461267, 0.0029592793])\n",
      "[INFO:] The anomaly threshold computed is  0.0029592793\n",
      "side: 28\n",
      "channel: 1\n",
      "\n",
      "Saving results for best after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//best/\n",
      "\n",
      "Saving results for worst after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//worst/\n",
      "[INFO:] The anomaly index are  [5944, 5982, 5925, 5968, 5930, 5939, 5979, 5945, 5943, 5972, 5922, 5926, 5934, 5978, 5966, 5928, 5963, 5953, 5977, 5965, 5929, 5921, 5955, 5959, 5960, 5948, 5952, 5940, 5931, 5967, 5924, 5956, 5927, 5923, 5950, 5933, 5973, 5958, 5974, 5946, 5936, 5981, 5941, 5957, 5962, 5980, 5938, 5964, 5920, 5975, 5947, 5970, 5942, 5951, 5976, 5961, 5935, 2977, 5954, 5949, 5971, 2683, 3834]\n",
      "=====================\n",
      "AUROC 0.1 0.9682539682539683\n",
      "=======================\n",
      "[INFO] compiling model...\n",
      "Train on 5384 samples, validate on 599 samples\n",
      "Epoch 1/350\n",
      "5384/5384 [==============================] - 44s 8ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 2/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 3/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 4/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 5/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 6/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6570 - val_loss: 8.6583\n",
      "Epoch 7/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 8/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 9/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6570 - val_loss: 8.6583\n",
      "Epoch 10/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 11/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 12/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 13/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 14/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 15/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 16/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 17/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 18/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 19/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6570 - val_loss: 8.6583\n",
      "Epoch 20/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 21/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 22/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 23/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 24/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 25/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 26/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6570 - val_loss: 8.6583\n",
      "Epoch 27/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 28/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 29/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 30/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 31/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 32/350\n",
      "5384/5384 [==============================] - 41s 8ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 33/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 34/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 35/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 36/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 37/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 38/350\n",
      "5384/5384 [==============================] - 41s 8ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 39/350\n",
      "5384/5384 [==============================] - 41s 8ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 40/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 41/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 42/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 43/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 44/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 45/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 46/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 47/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 48/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 49/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 50/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 51/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 52/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 53/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 54/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 55/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 56/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 57/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 58/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 59/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 60/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 61/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 62/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 63/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 64/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 65/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 66/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 67/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 68/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 69/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 70/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 71/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 72/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 73/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 74/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 75/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 76/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 77/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 78/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 79/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 80/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 81/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 82/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 83/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 84/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 85/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6583\n",
      "Epoch 86/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 87/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 88/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 89/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 90/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 91/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 92/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 93/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 94/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 95/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 96/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 97/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 98/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 99/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 100/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 101/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 102/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 103/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 104/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 105/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 106/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 107/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 108/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 109/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 110/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 111/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 112/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 113/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 114/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 115/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 116/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 117/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 118/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 119/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 120/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 121/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 122/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 123/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 124/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 125/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 126/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 127/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 128/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 129/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 130/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 131/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 133/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 134/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 135/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 136/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 137/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 138/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 139/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 140/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 141/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 142/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 143/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 144/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 145/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 146/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 147/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 148/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 149/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 150/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 151/350\n",
      "5384/5384 [==============================] - 41s 8ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 152/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 153/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 154/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 155/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 156/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 157/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 158/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 159/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 160/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 161/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 162/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 163/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 164/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 165/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 166/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 167/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 168/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 169/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 170/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 171/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 172/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 173/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 174/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 175/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 176/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 177/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 178/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 179/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 180/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 181/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 182/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 183/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 184/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 185/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 186/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 187/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 188/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 189/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 190/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 191/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 192/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 193/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 194/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 195/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 196/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 197/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 198/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 199/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 200/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 201/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 202/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 203/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 204/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6569 - val_loss: 8.6582\n",
      "Epoch 205/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 206/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 207/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 208/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 209/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 210/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 211/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 212/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 213/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 214/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 215/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 216/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 217/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 218/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 219/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 220/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 221/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 222/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 223/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 224/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 225/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 226/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 227/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 228/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 229/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 230/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 231/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 232/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 233/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 234/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 235/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 236/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 237/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 238/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 239/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 240/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 241/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 242/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 243/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 244/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 245/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 246/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 247/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 248/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 249/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 250/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 251/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 252/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 253/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 254/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 255/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 256/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 257/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 258/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 259/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 260/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 261/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 262/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6582\n",
      "Epoch 263/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 264/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 265/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 266/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 267/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 268/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 269/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 270/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 271/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 272/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 273/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 274/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 275/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 276/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 277/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 278/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 279/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 280/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 281/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 282/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 283/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 284/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 285/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 286/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 287/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 288/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 289/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 290/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 291/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 292/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 293/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 294/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 295/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 296/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 297/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6582\n",
      "Epoch 298/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 299/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 300/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 301/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 302/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 303/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 304/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 305/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 306/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 307/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 308/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 309/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 310/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 311/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 312/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 313/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 314/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 315/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 316/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 317/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 318/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 319/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 320/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 321/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 322/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 323/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 324/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 325/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 326/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 327/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 328/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 329/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 330/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 331/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 332/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 333/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 334/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 335/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 336/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 337/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 338/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 339/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 340/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 341/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 342/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 343/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 344/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 345/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 346/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 347/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 348/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "Epoch 349/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6567 - val_loss: 8.6581\n",
      "Epoch 350/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.6568 - val_loss: 8.6581\n",
      "(lamda,Threshold) 0.5 0.25\n",
      "The type of b is ..., its len is  <class 'numpy.ndarray'> (5983, 784) 784\n",
      "Iteration NUmber is :  0\n",
      "NUmber of non zero elements  for N,lamda 21017 0.5\n",
      "The shape of N (5983, 784)\n",
      "The minimum value of N  -0.5779681205749512\n",
      "The max value of N 0.7412124276161194\n",
      "[INFO:] Xclean  MSE Computed shape (5983, 784)\n",
      "[INFO:]Xdecoded  Computed shape (5983, 784)\n",
      "[INFO:] MSE Computed shape ()\n",
      "\n",
      " Mean square error Score ((Xclean, Xdecoded):\n",
      "dict_values([0.0038226442, 0.0032461267, 0.0029592793, 0.0027716826])\n",
      "[INFO:] The anomaly threshold computed is  0.0027716826\n",
      "side: 28\n",
      "channel: 1\n",
      "\n",
      "Saving results for best after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//best/\n",
      "\n",
      "Saving results for worst after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//worst/\n",
      "[INFO:] The anomaly index are  [5944, 5982, 5925, 5968, 5939, 5979, 5930, 5945, 5922, 5943, 5972, 5926, 5966, 5934, 5978, 5928, 5953, 5977, 5963, 5965, 5921, 5940, 5960, 5955, 5959, 5948, 5929, 5952, 5967, 5931, 5924, 5923, 5956, 5950, 5933, 5973, 5958, 5974, 5927, 5957, 5980, 5962, 5936, 5981, 5941, 5946, 5920, 5975, 5964, 5942, 5938, 5935, 5951, 5976, 5961, 5947, 5970, 2977, 5954, 5949, 5971, 3834, 2683]\n",
      "=====================\n",
      "AUROC 0.5 0.9682539682539683\n",
      "=======================\n",
      "[INFO] compiling model...\n",
      "Train on 5384 samples, validate on 599 samples\n",
      "Epoch 1/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 45s 8ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 2/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 3/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 4/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 5/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 6/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7923 - val_loss: 8.7936\n",
      "Epoch 7/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 8/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 9/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 10/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 11/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 12/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 13/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 14/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7923 - val_loss: 8.7936\n",
      "Epoch 15/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 16/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 17/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 18/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 19/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 20/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 21/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 22/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 23/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 24/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 25/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 26/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 27/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 28/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 29/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 30/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 31/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 32/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 33/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 34/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 35/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 36/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 37/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 38/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 39/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 40/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 41/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 42/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 43/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 44/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 45/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 46/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 47/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 48/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 49/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 50/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 51/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 52/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 53/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7923 - val_loss: 8.7936\n",
      "Epoch 54/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 55/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 56/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 57/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 58/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 59/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 60/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 61/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 62/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 63/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 64/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 65/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 66/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 67/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 68/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 69/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 70/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 71/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 72/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 73/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 74/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 75/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 76/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 77/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 78/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 79/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 80/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 81/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 82/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 83/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 84/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 85/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 86/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 87/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 88/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 89/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 90/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 91/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 92/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 93/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 94/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 95/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 96/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 97/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 98/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 99/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 100/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 101/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 102/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 103/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 104/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 105/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 106/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 107/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 108/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 109/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 110/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 111/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 112/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 113/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 114/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 115/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 116/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 117/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 118/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 119/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 120/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 121/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 122/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 123/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 124/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 125/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 126/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 127/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 128/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 129/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 130/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 131/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 132/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 133/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 134/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 135/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7936\n",
      "Epoch 136/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 137/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 138/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 139/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 140/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 141/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 142/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 143/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 144/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 145/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 146/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 147/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 148/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 149/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 150/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 151/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 152/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 153/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 154/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 155/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 156/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 157/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 158/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 159/350\n",
      "5384/5384 [==============================] - 41s 8ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 160/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 161/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 162/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 163/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 164/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 165/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 166/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 167/350\n",
      "5384/5384 [==============================] - 4230s 786ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 168/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 169/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 170/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 171/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 172/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 173/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 174/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 175/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 176/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 177/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 178/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 179/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 180/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 181/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 182/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 183/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 184/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 185/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 186/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 187/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 188/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 189/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 190/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 191/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 192/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 193/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 194/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 195/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 196/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 197/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 198/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 199/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 200/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 201/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 202/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 203/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 204/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 205/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 206/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 207/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 208/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 209/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 210/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 211/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 212/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 213/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 214/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 215/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 216/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 217/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 218/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 219/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 220/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 221/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 222/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 223/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 224/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 225/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 226/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 227/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 228/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 229/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 230/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 231/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 232/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 233/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 234/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 235/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 236/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 237/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 238/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 239/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 240/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 241/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 242/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 243/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 244/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 245/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 246/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 247/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 248/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 249/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 250/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 251/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 252/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 253/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 254/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 255/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 256/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 257/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 258/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 259/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 260/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 261/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 262/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 263/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 264/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 265/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 266/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 267/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 268/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 269/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 270/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 271/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 272/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 273/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 274/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 275/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 276/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 277/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 278/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 279/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 280/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 281/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 282/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 283/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 284/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 285/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 286/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 287/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 288/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 289/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 290/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 291/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 292/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 293/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 294/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 295/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 296/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 297/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 298/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 299/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 300/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 301/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7922 - val_loss: 8.7935\n",
      "Epoch 302/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 303/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 304/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 305/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 306/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 307/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 308/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 309/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 310/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 311/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 312/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 313/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 314/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 315/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 316/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 317/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 318/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 319/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 320/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 321/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 322/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 323/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 324/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 325/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 326/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 327/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 328/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 329/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 330/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 331/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 332/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 333/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 334/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 335/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 336/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 337/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 338/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 339/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 340/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 341/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 342/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 343/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 344/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 345/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 346/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 347/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 348/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 349/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "Epoch 350/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 8.7921 - val_loss: 8.7935\n",
      "(lamda,Threshold) 1.0 0.5\n",
      "The type of b is ..., its len is  <class 'numpy.ndarray'> (5983, 784) 784\n",
      "Iteration NUmber is :  0\n",
      "NUmber of non zero elements  for N,lamda 789 1.0\n",
      "The shape of N (5983, 784)\n",
      "The minimum value of N  -0.32428622245788574\n",
      "The max value of N 0.4911344051361084\n",
      "[INFO:] Xclean  MSE Computed shape (5983, 784)\n",
      "[INFO:]Xdecoded  Computed shape (5983, 784)\n",
      "[INFO:] MSE Computed shape ()\n",
      "\n",
      " Mean square error Score ((Xclean, Xdecoded):\n",
      "dict_values([0.0038226442, 0.0032461267, 0.0029592793, 0.0027716826, 0.002638992])\n",
      "[INFO:] The anomaly threshold computed is  0.002638992\n",
      "side: 28\n",
      "channel: 1\n",
      "\n",
      "Saving results for best after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//best/\n",
      "\n",
      "Saving results for worst after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//worst/\n",
      "[INFO:] The anomaly index are  [5944, 5982, 5925, 5968, 5930, 5939, 5979, 5945, 5922, 5943, 5972, 5926, 5934, 5978, 5966, 5963, 5928, 5953, 5977, 5921, 5965, 5940, 5960, 5959, 5948, 5955, 5952, 5929, 5967, 5931, 5923, 5933, 5973, 5950, 5924, 5956, 5958, 5974, 5927, 5962, 5980, 5936, 5981, 5957, 5941, 5946, 5920, 5975, 5942, 5964, 5935, 5951, 5976, 5961, 5938, 5947, 5970, 5954, 5949, 5971, 2977, 3834, 5937]\n",
      "=====================\n",
      "AUROC 1.0 0.9761904761904762\n",
      "=======================\n",
      "[INFO] compiling model...\n",
      "Train on 5384 samples, validate on 599 samples\n",
      "Epoch 1/350\n",
      "5384/5384 [==============================] - 41s 8ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 2/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 3/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 4/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 5/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 6/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 7/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 8/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 9/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 10/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 11/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 12/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 13/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 14/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 15/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 16/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 17/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 18/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 19/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 20/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 21/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 22/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 23/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 24/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 26/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 27/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 28/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 29/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 30/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 31/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 32/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 33/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 34/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 35/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 36/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 37/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 38/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 39/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 40/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 41/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 42/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 43/350\n",
      "5384/5384 [==============================] - 40s 8ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 44/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 45/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 46/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 47/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 48/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 49/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 50/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 51/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 52/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 53/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 54/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 55/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 56/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 57/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 58/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 59/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 60/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 61/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 62/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 63/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 64/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 65/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 66/350\n",
      "5384/5384 [==============================] - 40s 8ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 67/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 68/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 69/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 70/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 71/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 72/350\n",
      "5384/5384 [==============================] - 42s 8ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 73/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 74/350\n",
      "5384/5384 [==============================] - 41s 8ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 75/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 76/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 77/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 78/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 79/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 80/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 81/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 82/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 83/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 84/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 85/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 86/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 87/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7893\n",
      "Epoch 88/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 89/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 90/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 91/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 92/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 93/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 94/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7878 - val_loss: 6.7893\n",
      "Epoch 95/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 96/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 97/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 98/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 99/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 100/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7879 - val_loss: 6.7893\n",
      "Epoch 101/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 102/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 104/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 105/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 106/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 107/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 108/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 109/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 110/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 111/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 112/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 113/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 114/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 115/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 116/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 117/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 118/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 119/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 120/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 121/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 122/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 123/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 124/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 125/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 126/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 127/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 128/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 129/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 130/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 131/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 132/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 133/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 134/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 135/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 136/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 137/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 138/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 139/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 140/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 141/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 142/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 143/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 144/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 145/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 146/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 147/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 148/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 149/350\n",
      "5384/5384 [==============================] - 42s 8ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 150/350\n",
      "5384/5384 [==============================] - 41s 8ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 151/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 152/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 153/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 154/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 155/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 156/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 157/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 158/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 159/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 160/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 161/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 162/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 163/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 164/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 165/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 166/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 167/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 168/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 169/350\n",
      "5384/5384 [==============================] - 43s 8ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 170/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 171/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 172/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 173/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 174/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 175/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 176/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 177/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 178/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 179/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 180/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 181/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 182/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 183/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 184/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 185/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 186/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 187/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 188/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 189/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 190/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 191/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 192/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 193/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 194/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 195/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 196/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 197/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 198/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 199/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 200/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 201/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 202/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 203/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 204/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 205/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 206/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 207/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 208/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 209/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 210/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 211/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 212/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 213/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 214/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 215/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 216/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 217/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 218/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 219/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 220/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 221/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 222/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 223/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 224/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 225/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 226/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 227/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 228/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 229/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 230/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 231/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 232/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 233/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 234/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 235/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 236/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 237/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 238/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 239/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 240/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 241/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 242/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 243/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 244/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 245/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 246/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 247/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 248/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 249/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 250/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 251/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 252/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 253/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 254/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 255/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 256/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 257/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 258/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 259/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 260/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 261/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 262/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 263/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 264/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 265/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 266/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 267/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 268/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 269/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 270/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 271/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7879 - val_loss: 6.7892\n",
      "Epoch 272/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 273/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 274/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 275/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 276/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 277/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 278/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 279/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 280/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 281/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 282/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 283/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 284/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 285/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 286/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 287/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 288/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 289/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 290/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 291/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 292/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 293/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 294/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 295/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 296/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 297/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 298/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 299/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 300/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 301/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 302/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 303/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 304/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 305/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 306/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 307/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 308/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 309/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 310/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 311/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 312/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 313/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 314/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 315/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 316/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 317/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 318/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 319/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 320/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 321/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 322/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 323/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 324/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 325/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 326/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 327/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 328/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 329/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 330/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 331/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 332/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 333/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 334/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 335/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 336/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 337/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 338/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 339/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 340/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 341/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 342/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 343/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 344/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 345/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 346/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 347/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 348/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 349/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "Epoch 350/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 6.7878 - val_loss: 6.7892\n",
      "(lamda,Threshold) 10.0 5.0\n",
      "The type of b is ..., its len is  <class 'numpy.ndarray'> (5983, 784) 784\n",
      "Iteration NUmber is :  0\n",
      "NUmber of non zero elements  for N,lamda 0 10.0\n",
      "The shape of N (5983, 784)\n",
      "The minimum value of N  0.0\n",
      "The max value of N 0.0\n",
      "[INFO:] Xclean  MSE Computed shape (5983, 784)\n",
      "[INFO:]Xdecoded  Computed shape (5983, 784)\n",
      "[INFO:] MSE Computed shape ()\n",
      "\n",
      " Mean square error Score ((Xclean, Xdecoded):\n",
      "dict_values([0.0038226442, 0.0032461267, 0.0029592793, 0.0027716826, 0.002638992, 0.0025306442])\n",
      "[INFO:] The anomaly threshold computed is  0.0025306442\n",
      "side: 28\n",
      "channel: 1\n",
      "\n",
      "Saving results for best after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//best/\n",
      "\n",
      "Saving results for worst after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//worst/\n",
      "[INFO:] The anomaly index are  [5982, 5944, 5968, 5925, 5930, 5939, 5979, 5922, 5945, 5943, 5972, 5926, 5934, 5978, 5963, 5966, 5928, 5953, 5977, 5921, 5940, 5960, 5959, 5965, 5955, 5948, 5929, 5952, 5967, 5933, 5973, 5923, 5950, 5931, 5924, 5956, 5958, 5974, 5927, 5962, 5980, 5936, 5981, 5957, 5941, 5942, 5920, 5975, 5935, 5951, 5976, 5961, 5964, 5946, 5947, 5970, 5938, 5949, 5971, 5954, 2977, 3834, 5937]\n",
      "=====================\n",
      "AUROC 10.0 0.9761904761904762\n",
      "=======================\n",
      "[INFO] compiling model...\n",
      "Train on 5384 samples, validate on 599 samples\n",
      "Epoch 1/350\n",
      "5384/5384 [==============================] - 42s 8ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 2/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 3/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 4/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 5/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 6/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 7/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 8/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 9/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 10/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 11/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 12/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 13/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 14/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 15/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 16/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 17/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 18/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 19/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 20/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 21/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 22/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 23/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 24/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 25/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 26/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 27/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 28/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 29/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 30/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 31/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 32/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 33/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 34/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 35/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 36/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9530\n",
      "Epoch 37/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 38/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 39/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 40/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 41/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 42/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 43/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 44/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 45/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 46/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 47/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 48/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 49/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 50/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 51/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 52/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 53/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 54/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 55/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 56/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 57/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 58/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 59/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9530\n",
      "Epoch 60/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 61/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 62/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 63/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 64/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 65/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 66/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 67/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 68/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 69/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 70/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 71/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 72/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 73/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 74/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 75/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 76/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 77/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 78/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9530\n",
      "Epoch 79/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 80/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 81/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 82/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 83/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 84/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 85/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 86/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9530\n",
      "Epoch 87/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 88/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 89/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 90/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 91/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 92/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 93/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 94/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 95/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 96/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 97/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 98/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 99/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 100/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 101/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 102/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 103/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 104/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 105/350\n",
      "5384/5384 [==============================] - 43s 8ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 106/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 107/350\n",
      "5384/5384 [==============================] - 40s 8ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 108/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 109/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 110/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 111/350\n",
      "5384/5384 [==============================] - 47s 9ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 112/350\n",
      "5384/5384 [==============================] - 45s 8ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 113/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 114/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 115/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 116/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 117/350\n",
      "5384/5384 [==============================] - 42s 8ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 118/350\n",
      "5384/5384 [==============================] - 43s 8ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 119/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 120/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 121/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 122/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 123/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 124/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 125/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 126/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 127/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 128/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 129/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 130/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 131/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 132/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 133/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 134/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 135/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 136/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 137/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 138/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 139/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 140/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 141/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 142/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 143/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 144/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 145/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 146/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 147/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 148/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 149/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 150/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 151/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 152/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 153/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 154/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 155/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 156/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 157/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 158/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 159/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 160/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 161/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 162/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 163/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 164/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 165/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 166/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 167/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 168/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 169/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 170/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 171/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 172/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 173/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 174/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 175/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 176/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 177/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 178/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 179/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 180/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 181/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 182/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 183/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 184/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 185/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 186/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 187/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 188/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 189/350\n",
      "5384/5384 [==============================] - 39s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 190/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 191/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 192/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 193/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 194/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 195/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 196/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 197/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 198/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 199/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 200/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 201/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 202/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 203/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 204/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 205/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 206/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 207/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 208/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 209/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 210/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 211/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 212/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 213/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 214/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 215/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 216/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 217/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 218/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 219/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 220/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 221/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 222/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 223/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 224/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 225/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 226/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 227/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 228/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 229/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 230/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 231/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 232/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 233/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 234/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 235/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 236/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 237/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 238/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 239/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 240/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 241/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9516 - val_loss: 4.9529\n",
      "Epoch 242/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 243/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 244/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 245/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 246/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 247/350\n",
      "5384/5384 [==============================] - 33s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 248/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 249/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 250/350\n",
      "5384/5384 [==============================] - 2941s 546ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 251/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 252/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 253/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 254/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 255/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 256/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 257/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 258/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 259/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 260/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 261/350\n",
      "5384/5384 [==============================] - 32s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 262/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 263/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 264/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 265/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 266/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 267/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 268/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 269/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 270/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 271/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 272/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 273/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 274/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 275/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 276/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 277/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 278/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 279/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 280/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 281/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 282/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 283/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 284/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 285/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 286/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 287/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 288/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 289/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 290/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 291/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 292/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 293/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 294/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 295/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 296/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 297/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 298/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 299/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 300/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 301/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 302/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 303/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 304/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 305/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 306/350\n",
      "5384/5384 [==============================] - 30s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 307/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 308/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 309/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 310/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 311/350\n",
      "5384/5384 [==============================] - 31s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 312/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 313/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 314/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 315/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 316/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 317/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 318/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 319/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 320/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 321/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 322/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 323/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 324/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 325/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 326/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 327/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 328/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 329/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 330/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 331/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 332/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 333/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 334/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 335/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 336/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 337/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 338/350\n",
      "5384/5384 [==============================] - 34s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 339/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 340/350\n",
      "5384/5384 [==============================] - 40s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 341/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 342/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 343/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 344/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 345/350\n",
      "5384/5384 [==============================] - 35s 6ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 346/350\n",
      "5384/5384 [==============================] - 36s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 347/350\n",
      "5384/5384 [==============================] - 38s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 348/350\n",
      "5384/5384 [==============================] - 37s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 349/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "Epoch 350/350\n",
      "5384/5384 [==============================] - 35s 7ms/step - loss: 4.9515 - val_loss: 4.9529\n",
      "(lamda,Threshold) 100.0 50.0\n",
      "The type of b is ..., its len is  <class 'numpy.ndarray'> (5983, 784) 784\n",
      "Iteration NUmber is :  0\n",
      "NUmber of non zero elements  for N,lamda 0 100.0\n",
      "The shape of N (5983, 784)\n",
      "The minimum value of N  0.0\n",
      "The max value of N 0.0\n",
      "[INFO:] Xclean  MSE Computed shape (5983, 784)\n",
      "[INFO:]Xdecoded  Computed shape (5983, 784)\n",
      "[INFO:] MSE Computed shape ()\n",
      "\n",
      " Mean square error Score ((Xclean, Xdecoded):\n",
      "dict_values([0.0038226442, 0.0032461267, 0.0029592793, 0.0027716826, 0.002638992, 0.0025306442, 0.0024485346])\n",
      "[INFO:] The anomaly threshold computed is  0.0024485346\n",
      "side: 28\n",
      "channel: 1\n",
      "\n",
      "Saving results for best after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//best/\n",
      "\n",
      "Saving results for worst after being encoded and decoded: @\n",
      "../reports/figures/MNIST/RCAE//worst/\n",
      "[INFO:] The anomaly index are  [5944, 5982, 5968, 5925, 5930, 5939, 5979, 5922, 5945, 5943, 5972, 5926, 5963, 5934, 5978, 5966, 5928, 5953, 5977, 5921, 5960, 5959, 5940, 5965, 5948, 5955, 5952, 5929, 5967, 5923, 5933, 5973, 5950, 5931, 5924, 5956, 5958, 5974, 5927, 5962, 5980, 5936, 5981, 5942, 5957, 5961, 5951, 5976, 5941, 5935, 5920, 5975, 5947, 5970, 5964, 5946, 5938, 5949, 5971, 5954, 2977, 5937, 3834]\n",
      "=====================\n",
      "AUROC 100.0 0.9761904761904762\n",
      "=======================\n",
      "\n",
      " Mean square error Score ((Xclean, Xdecoded):\n",
      "dict_values([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Obtaining the training and testing data\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.models.RCAE import RCAE_AD\n",
    "\n",
    "DATASET = \"mnist\"\n",
    "IMG_DIM= 784\n",
    "IMG_HGT =28\n",
    "IMG_WDT=28\n",
    "IMG_CHANNEL=1\n",
    "HIDDEN_LAYER_SIZE= 32\n",
    "MODEL_SAVE_PATH = PROJECT_DIR + \"/models/MNIST/RCAE/\"\n",
    "REPORT_SAVE_PATH = PROJECT_DIR + \"/reports/figures/MNIST/RCAE/\"\n",
    "PRETRAINED_WT_PATH = \"\"\n",
    "\n",
    "rcae = RCAE_AD(DATASET,IMG_DIM, HIDDEN_LAYER_SIZE, IMG_HGT, IMG_WDT,IMG_CHANNEL, MODEL_SAVE_PATH, REPORT_SAVE_PATH,PRETRAINED_WT_PATH)\n",
    "\n",
    "print(\"Train Data Shape: \",rcae.data._X_train.shape)\n",
    "print(\"Train Label Shape: \",rcae.data._y_train.shape)\n",
    "print(\"Validation Data Shape: \",rcae.data._X_val.shape)\n",
    "print(\"Validation Label Shape: \",rcae.data._y_val.shape)\n",
    "print(\"Test Data Shape: \",rcae.data._X_test.shape)\n",
    "print(\"Test Label Shape: \",rcae.data._y_test.shape)\n",
    "print(\"===========TRAINING AND PREDICTING WITH RCAE============================\")\n",
    "rcae.fit_and_predict()\n",
    "print(\"========================================================================\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7deea1159869>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m## Prepare the data for pretraining CAE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mx_trainForWtInit\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainX' is not defined"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "DATASET = \"MNIST\"\n",
    "IMG_DIM= 784\n",
    "IMG_HGT =28\n",
    "IMG_WDT=28\n",
    "IMG_CHANNEL=1\n",
    "HIDDEN_LAYER_SIZE= 128\n",
    "MODEL_SAVE_PATH = PROJECT_DIR + \"/models/MNIST/Deep_SVDD/\"\n",
    "REPORT_SAVE_PATH = PROJECT_DIR + \"/reports/figures/MNIST/Deep_SVDD/\"\n",
    "PRETRAINED_WT_PATH = \"\"\n",
    "\n",
    "## Prepare the data for pretraining CAE\n",
    "x_train = trainX.reshape((len(trainX), 28, 28, 1))\n",
    "x_trainForWtInit= x_train\n",
    "\n",
    "test_ones = test_ones.reshape((len(test_ones), 28, 28, 1))\n",
    "test_sevens = test_sevens.reshape((len(test_sevens), 28, 28, 1))\n",
    "x_test = np.concatenate((test_ones,test_sevens))\n",
    "\n",
    "print(\"Reshaped Training samples for CAE\",x_train.shape)\n",
    "print(\"Reshaped Testing samples for CAE\",x_test.shape)\n",
    "\n",
    "from src.models.Deep_SVDD import Deep_SVDD\n",
    "deep_svdd =   Deep_SVDD(DATASET,x_trainForWtInit,IMG_DIM,HIDDEN_LAYER_SIZE,IMG_HGT,IMG_WDT,IMG_CHANNEL,MODEL_SAVE_PATH,REPORT_SAVE_PATH,PRETRAINED_WT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Deep_SVDD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test  FF_NN Model Supervised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_Anomaly_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-cee4a7dae6a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mREPORT_SAVE_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPROJECT_DIR\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/reports/figures/MNIST/FF_NN/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO]\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_Anomaly_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Anomalous Samples Appended to training set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mdata_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_Anomaly_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdata_train_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_Anomaly_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_Anomaly_X' is not defined"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "IMG_DIM= 784\n",
    "IMG_HGT =28\n",
    "IMG_WDT=28\n",
    "IMG_DEPTH=1\n",
    "HIDDEN_LAYER_SIZE=196\n",
    "\n",
    "MODEL_SAVE_PATH = PROJECT_DIR + \"/models/MNIST/FF_NN/\"\n",
    "REPORT_SAVE_PATH = PROJECT_DIR + \"/reports/figures/MNIST/FF_NN/\"\n",
    "\n",
    "print(\"[INFO]\",train_Anomaly_X.shape[0],\"Anomalous Samples Appended to training set\")\n",
    "data_train = np.concatenate((trainX,train_Anomaly_X),axis=0)\n",
    "data_train_label = np.concatenate((trainY,train_Anomaly_Y),axis=0)\n",
    "print(\"[INFO]\",data_train.shape[0],\"Training Samples Contains both 1's and 7s\")\n",
    "nClass =2\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "clf_FF_NN =  FF_NN(IMG_DIM,HIDDEN_LAYER_SIZE,IMG_HGT,IMG_WDT,MODEL_SAVE_PATH,REPORT_SAVE_PATH)\n",
    "clf_FF_NN.fit(data_train,data_train_label,NUM_EPOCHS,IMG_HGT,IMG_WDT,IMG_DEPTH,nClass)\n",
    "\n",
    "## Predict the scores \n",
    "auc_FF_NN = clf_FF_NN.score(test_ones,label_ones,test_sevens,label_sevens)\n",
    "print(\"===========\")\n",
    "print(\"AUC: \",auc_FF_NN)\n",
    "print(\"===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FakeNoise FF_NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] 5000 Noise Samples Appended for training set\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "[INFO] serializing network...\n",
      "[INFO] loading network...\n",
      "5050 Actual test samples\n",
      "5050 Predicted test samples\n",
      "===================================\n",
      "auccary_score: 0.8998019801980198\n",
      "roc_auc_score: 0.5534\n",
      "y_true [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_pred [1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0\n",
      " 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0]\n",
      "===================================\n",
      "===========\n",
      "AUC:  0.5534\n",
      "===========\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Fake Noise data to be generated which will be added to the training set before training\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "IMG_DIM= 784\n",
    "IMG_HGT =28\n",
    "IMG_WDT=28\n",
    "IMG_DEPTH=1\n",
    "HIDDEN_LAYER_SIZE=196\n",
    "\n",
    "MODEL_SAVE_PATH = PROJECT_DIR + \"/models/MNIST/FAKE_NOISE_FF_NN/\"\n",
    "REPORT_SAVE_PATH = PROJECT_DIR + \"/reports/figures/MNIST/FAKE_NOISE_FF_NN/\"\n",
    "\n",
    "\n",
    "from src.models.Fake_Noise_FF_NN import Fake_Noise_FF_NN\n",
    "## Remove the Anomalous data and instead add Noise\n",
    "X_Noise,X_NoiseLabel = createData.get_FAKE_Noise_MNIST_TrainingData(trainX)\n",
    "print(\"[INFO]\",X_Noise.shape[0],\"Noise Samples Appended for training set\")\n",
    "data_train = np.concatenate((trainX,X_Noise),axis=0)\n",
    "data_train_label = np.concatenate((trainY,X_NoiseLabel),axis=0)\n",
    "\n",
    "\n",
    "clf_FakeNoise_FF_NN =   Fake_Noise_FF_NN(IMG_DIM,HIDDEN_LAYER_SIZE,IMG_HGT,IMG_WDT,MODEL_SAVE_PATH,REPORT_SAVE_PATH)\n",
    "clf_FakeNoise_FF_NN.fit(data_train,data_train_label,NUM_EPOCHS,IMG_HGT,IMG_WDT,IMG_DEPTH,nClass)\n",
    "# Predict the scores \n",
    "\n",
    "auc_FAKENOISE_FF_NN = clf_FakeNoise_FF_NN.score(test_ones,label_ones,test_sevens,label_sevens)\n",
    "print(\"===========\")\n",
    "print(\"AUC: \",auc_FAKENOISE_FF_NN)\n",
    "print(\"===========\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKlearn OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the OCSVM classifier.....\n",
      "===================================\n",
      "AUC: 0.7869240000000001\n",
      "===================================\n",
      "Training the OCSVM classifier.....\n",
      "===================================\n",
      "AUC: 0.9705560000000001\n",
      "===================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "##create the classifier\n",
    "from src.models.ocsvmSklearn import OCSVM\n",
    "IMG_HGT =28\n",
    "IMG_WDT=28\n",
    "ocsvm = OCSVM(IMG_HGT,IMG_WDT)\n",
    "nu= 0.01\n",
    "kernel = 'linear'\n",
    "clf = ocsvm.fit(trainX,nu,kernel)\n",
    "res = ocsvm.score(clf,test_ones,test_sevens)\n",
    "auc_OCSVM_linear = res\n",
    "print(\"=\"*35)\n",
    "print(\"AUC:\",res)\n",
    "print(\"=\"*35)\n",
    "\n",
    "kernel = 'rbf'\n",
    "clf = ocsvm.fit(trainX,nu,kernel)\n",
    "res = ocsvm.score(clf,test_ones,test_sevens)\n",
    "auc_OCSVM_rbf = res\n",
    "print(\"=\"*35)\n",
    "print(\"AUC:\",res)\n",
    "print(\"=\"*35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OC-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO]  (196,) input  --> hidden layer weights shape ...\n",
      "[INFO]  (2,) hidden --> output layer weights shape ...\n",
      "[INFO] training network...\n",
      "Train on 4500 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "4500/4500 [==============================] - 0s 63us/step - loss: 44.2036 - val_loss: 43.6791\n",
      "evaluation for epoch: 0\n",
      "output: Tensor(\"Print:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 2/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 44.1708 - val_loss: 43.7103\n",
      "evaluation for epoch: 1\n",
      "output: Tensor(\"Print_1:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 3/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 44.1486 - val_loss: 43.7392\n",
      "evaluation for epoch: 2\n",
      "output: Tensor(\"Print_2:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 4/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 44.1274 - val_loss: 43.7661\n",
      "evaluation for epoch: 3\n",
      "output: Tensor(\"Print_3:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 5/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 44.1070 - val_loss: 43.7910\n",
      "evaluation for epoch: 4\n",
      "output: Tensor(\"Print_4:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 6/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 44.0875 - val_loss: 43.8141\n",
      "evaluation for epoch: 5\n",
      "output: Tensor(\"Print_5:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 7/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 44.0683 - val_loss: 43.8355\n",
      "evaluation for epoch: 6\n",
      "output: Tensor(\"Print_6:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 8/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 44.0497 - val_loss: 43.8560\n",
      "evaluation for epoch: 7\n",
      "output: Tensor(\"Print_7:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 9/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 44.0315 - val_loss: 43.8742\n",
      "evaluation for epoch: 8\n",
      "output: Tensor(\"Print_8:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 10/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 44.0135 - val_loss: 43.8920\n",
      "evaluation for epoch: 9\n",
      "output: Tensor(\"Print_9:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 11/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.9958 - val_loss: 43.9087\n",
      "evaluation for epoch: 10\n",
      "output: Tensor(\"Print_10:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 12/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.9783 - val_loss: 43.9235\n",
      "evaluation for epoch: 11\n",
      "output: Tensor(\"Print_11:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 13/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.9610 - val_loss: 43.9383\n",
      "evaluation for epoch: 12\n",
      "output: Tensor(\"Print_12:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 14/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.9438 - val_loss: 43.9518\n",
      "evaluation for epoch: 13\n",
      "output: Tensor(\"Print_13:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 15/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.9268 - val_loss: 43.9646\n",
      "evaluation for epoch: 14\n",
      "output: Tensor(\"Print_14:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 16/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.9098 - val_loss: 43.9768\n",
      "evaluation for epoch: 15\n",
      "output: Tensor(\"Print_15:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 17/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.8930 - val_loss: 43.9876\n",
      "evaluation for epoch: 16\n",
      "output: Tensor(\"Print_16:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 18/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.8763 - val_loss: 43.9983\n",
      "evaluation for epoch: 17\n",
      "output: Tensor(\"Print_17:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 19/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.8597 - val_loss: 44.0087\n",
      "evaluation for epoch: 18\n",
      "output: Tensor(\"Print_18:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 20/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.8431 - val_loss: 44.0186\n",
      "evaluation for epoch: 19\n",
      "output: Tensor(\"Print_19:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 21/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.8266 - val_loss: 44.0276\n",
      "evaluation for epoch: 20\n",
      "output: Tensor(\"Print_20:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 22/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.8102 - val_loss: 44.0363\n",
      "evaluation for epoch: 21\n",
      "output: Tensor(\"Print_21:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 23/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.7938 - val_loss: 44.0446\n",
      "evaluation for epoch: 22\n",
      "output: Tensor(\"Print_22:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 24/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.7775 - val_loss: 44.0524\n",
      "evaluation for epoch: 23\n",
      "output: Tensor(\"Print_23:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 25/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.7613 - val_loss: 44.0602\n",
      "evaluation for epoch: 24\n",
      "output: Tensor(\"Print_24:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 26/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 43.7450 - val_loss: 44.0676\n",
      "evaluation for epoch: 25\n",
      "output: Tensor(\"Print_25:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 27/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.7290 - val_loss: 44.0743\n",
      "evaluation for epoch: 26\n",
      "output: Tensor(\"Print_26:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 28/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.7129 - val_loss: 44.0810\n",
      "evaluation for epoch: 27\n",
      "output: Tensor(\"Print_27:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 29/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.6969 - val_loss: 44.0873\n",
      "evaluation for epoch: 28\n",
      "output: Tensor(\"Print_28:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 30/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.6810 - val_loss: 44.0933\n",
      "evaluation for epoch: 29\n",
      "output: Tensor(\"Print_29:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 31/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.6651 - val_loss: 44.0989\n",
      "evaluation for epoch: 30\n",
      "output: Tensor(\"Print_30:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 32/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.6492 - val_loss: 44.1047\n",
      "evaluation for epoch: 31\n",
      "output: Tensor(\"Print_31:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 33/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.6334 - val_loss: 44.1100\n",
      "evaluation for epoch: 32\n",
      "output: Tensor(\"Print_32:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 34/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.6176 - val_loss: 44.1152\n",
      "evaluation for epoch: 33\n",
      "output: Tensor(\"Print_33:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 35/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.6019 - val_loss: 44.1201\n",
      "evaluation for epoch: 34\n",
      "output: Tensor(\"Print_34:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 36/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 43.5862 - val_loss: 44.1254\n",
      "evaluation for epoch: 35\n",
      "output: Tensor(\"Print_35:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 37/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.5705 - val_loss: 44.1299\n",
      "evaluation for epoch: 36\n",
      "output: Tensor(\"Print_36:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 38/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.5548 - val_loss: 44.1340\n",
      "evaluation for epoch: 37\n",
      "output: Tensor(\"Print_37:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 39/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.5392 - val_loss: 44.1384\n",
      "evaluation for epoch: 38\n",
      "output: Tensor(\"Print_38:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 40/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.5235 - val_loss: 44.1428\n",
      "evaluation for epoch: 39\n",
      "output: Tensor(\"Print_39:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 41/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.5081 - val_loss: 44.1472\n",
      "evaluation for epoch: 40\n",
      "output: Tensor(\"Print_40:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 42/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.4925 - val_loss: 44.1508\n",
      "evaluation for epoch: 41\n",
      "output: Tensor(\"Print_41:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 43/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 43.4770 - val_loss: 44.1549\n",
      "evaluation for epoch: 42\n",
      "output: Tensor(\"Print_42:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 44/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 43.4615 - val_loss: 44.1586\n",
      "evaluation for epoch: 43\n",
      "output: Tensor(\"Print_43:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 45/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.4460 - val_loss: 44.1624\n",
      "evaluation for epoch: 44\n",
      "output: Tensor(\"Print_44:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 46/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.4305 - val_loss: 44.1662\n",
      "evaluation for epoch: 45\n",
      "output: Tensor(\"Print_45:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 47/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 43.4151 - val_loss: 44.1692\n",
      "evaluation for epoch: 46\n",
      "output: Tensor(\"Print_46:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 48/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 43.3998 - val_loss: 44.1723\n",
      "evaluation for epoch: 47\n",
      "output: Tensor(\"Print_47:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 49/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 43.3843 - val_loss: 44.1755\n",
      "evaluation for epoch: 48\n",
      "output: Tensor(\"Print_48:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 50/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 43.3690 - val_loss: 44.1785\n",
      "evaluation for epoch: 49\n",
      "output: Tensor(\"Print_49:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 51/100\n",
      "4500/4500 [==============================] - 0s 28us/step - loss: 43.3536 - val_loss: 44.1808\n",
      "evaluation for epoch: 50\n",
      "output: Tensor(\"Print_50:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 52/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.3383 - val_loss: 44.1833\n",
      "evaluation for epoch: 51\n",
      "output: Tensor(\"Print_51:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 53/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.3230 - val_loss: 44.1867\n",
      "evaluation for epoch: 52\n",
      "output: Tensor(\"Print_52:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 54/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.3077 - val_loss: 44.1901\n",
      "evaluation for epoch: 53\n",
      "output: Tensor(\"Print_53:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 55/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.2924 - val_loss: 44.1927\n",
      "evaluation for epoch: 54\n",
      "output: Tensor(\"Print_54:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 56/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.2772 - val_loss: 44.1949\n",
      "evaluation for epoch: 55\n",
      "output: Tensor(\"Print_55:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 57/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.2620 - val_loss: 44.1971\n",
      "evaluation for epoch: 56\n",
      "output: Tensor(\"Print_56:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 58/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.2467 - val_loss: 44.1995\n",
      "evaluation for epoch: 57\n",
      "output: Tensor(\"Print_57:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 59/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.2315 - val_loss: 44.2022\n",
      "evaluation for epoch: 58\n",
      "output: Tensor(\"Print_58:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 60/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.2163 - val_loss: 44.2043\n",
      "evaluation for epoch: 59\n",
      "output: Tensor(\"Print_59:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 61/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.2012 - val_loss: 44.2068\n",
      "evaluation for epoch: 60\n",
      "output: Tensor(\"Print_60:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 62/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.1860 - val_loss: 44.2088\n",
      "evaluation for epoch: 61\n",
      "output: Tensor(\"Print_61:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 63/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.1708 - val_loss: 44.2115\n",
      "evaluation for epoch: 62\n",
      "output: Tensor(\"Print_62:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 64/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.1557 - val_loss: 44.2135\n",
      "evaluation for epoch: 63\n",
      "output: Tensor(\"Print_63:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 65/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.1406 - val_loss: 44.2155\n",
      "evaluation for epoch: 64\n",
      "output: Tensor(\"Print_64:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 66/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.1255 - val_loss: 44.2175\n",
      "evaluation for epoch: 65\n",
      "output: Tensor(\"Print_65:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 67/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.1105 - val_loss: 44.2191\n",
      "evaluation for epoch: 66\n",
      "output: Tensor(\"Print_66:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 68/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.0953 - val_loss: 44.2209\n",
      "evaluation for epoch: 67\n",
      "output: Tensor(\"Print_67:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 69/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.0802 - val_loss: 44.2227\n",
      "evaluation for epoch: 68\n",
      "output: Tensor(\"Print_68:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 70/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.0652 - val_loss: 44.2248\n",
      "evaluation for epoch: 69\n",
      "output: Tensor(\"Print_69:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 71/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 43.0502 - val_loss: 44.2263\n",
      "evaluation for epoch: 70\n",
      "output: Tensor(\"Print_70:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 72/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.0350 - val_loss: 44.2279\n",
      "evaluation for epoch: 71\n",
      "output: Tensor(\"Print_71:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 73/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.0201 - val_loss: 44.2291\n",
      "evaluation for epoch: 72\n",
      "output: Tensor(\"Print_72:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 74/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 43.0051 - val_loss: 44.2304\n",
      "evaluation for epoch: 73\n",
      "output: Tensor(\"Print_73:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 75/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.9900 - val_loss: 44.2318\n",
      "evaluation for epoch: 74\n",
      "output: Tensor(\"Print_74:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 76/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.9750 - val_loss: 44.2337\n",
      "evaluation for epoch: 75\n",
      "output: Tensor(\"Print_75:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 77/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.9601 - val_loss: 44.2353\n",
      "evaluation for epoch: 76\n",
      "output: Tensor(\"Print_76:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 78/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 42.9451 - val_loss: 44.2366\n",
      "evaluation for epoch: 77\n",
      "output: Tensor(\"Print_77:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 79/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.9301 - val_loss: 44.2378\n",
      "evaluation for epoch: 78\n",
      "output: Tensor(\"Print_78:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 80/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 42.9153 - val_loss: 44.2391\n",
      "evaluation for epoch: 79\n",
      "output: Tensor(\"Print_79:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 81/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.9004 - val_loss: 44.2408\n",
      "evaluation for epoch: 80\n",
      "output: Tensor(\"Print_80:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 82/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 42.8855 - val_loss: 44.2420\n",
      "evaluation for epoch: 81\n",
      "output: Tensor(\"Print_81:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 83/100\n",
      "4500/4500 [==============================] - 0s 32us/step - loss: 42.8707 - val_loss: 44.2429\n",
      "evaluation for epoch: 82\n",
      "output: Tensor(\"Print_82:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 84/100\n",
      "4500/4500 [==============================] - 0s 31us/step - loss: 42.8558 - val_loss: 44.2441\n",
      "evaluation for epoch: 83\n",
      "output: Tensor(\"Print_83:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 85/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.8410 - val_loss: 44.2451\n",
      "evaluation for epoch: 84\n",
      "output: Tensor(\"Print_84:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500/4500 [==============================] - 0s 31us/step - loss: 42.8262 - val_loss: 44.2463\n",
      "evaluation for epoch: 85\n",
      "output: Tensor(\"Print_85:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 87/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.8114 - val_loss: 44.2472\n",
      "evaluation for epoch: 86\n",
      "output: Tensor(\"Print_86:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 88/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.7966 - val_loss: 44.2481\n",
      "evaluation for epoch: 87\n",
      "output: Tensor(\"Print_87:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 89/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.7819 - val_loss: 44.2487\n",
      "evaluation for epoch: 88\n",
      "output: Tensor(\"Print_88:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 90/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.7671 - val_loss: 44.2499\n",
      "evaluation for epoch: 89\n",
      "output: Tensor(\"Print_89:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 91/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 42.7523 - val_loss: 44.2506\n",
      "evaluation for epoch: 90\n",
      "output: Tensor(\"Print_90:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 92/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.7376 - val_loss: 44.2513\n",
      "evaluation for epoch: 91\n",
      "output: Tensor(\"Print_91:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 93/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 42.7229 - val_loss: 44.2522\n",
      "evaluation for epoch: 92\n",
      "output: Tensor(\"Print_92:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 94/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 42.7082 - val_loss: 44.2533\n",
      "evaluation for epoch: 93\n",
      "output: Tensor(\"Print_93:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 95/100\n",
      "4500/4500 [==============================] - 0s 29us/step - loss: 42.6934 - val_loss: 44.2529\n",
      "evaluation for epoch: 94\n",
      "output: Tensor(\"Print_94:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 96/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.6788 - val_loss: 44.2538\n",
      "evaluation for epoch: 95\n",
      "output: Tensor(\"Print_95:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 97/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.6641 - val_loss: 44.2544\n",
      "evaluation for epoch: 96\n",
      "output: Tensor(\"Print_96:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 98/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.6494 - val_loss: 44.2557\n",
      "evaluation for epoch: 97\n",
      "output: Tensor(\"Print_97:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 99/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.6347 - val_loss: 44.2564\n",
      "evaluation for epoch: 98\n",
      "output: Tensor(\"Print_98:0\", shape=(?, 2), dtype=float32)\n",
      "Epoch 100/100\n",
      "4500/4500 [==============================] - 0s 30us/step - loss: 42.6200 - val_loss: 44.2568\n",
      "evaluation for epoch: 99\n",
      "output: Tensor(\"Print_99:0\", shape=(?, 2), dtype=float32)\n",
      "[INFO] serializing network and saving trained weights...\n",
      "[INFO] Saving model layer weights...\n",
      "[INFO] loading network...\n",
      "5050 Actual test samples\n",
      "===================================\n",
      "auccary_score: 0.9984158415841584\n",
      "roc_auc_score: 0.9199999999999999\n",
      "y_true [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "y_pred [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 0]\n",
      "===================================\n",
      "===================================\n",
      "AUC: 0.9199999999999999\n",
      "===================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raghav/envPython3/lib/python3.6/site-packages/keras/engine/sequential.py:252: UserWarning: Network returning invalid probability values. The last layer might not normalize predictions into probabilities (like softmax or sigmoid would).\n",
      "  warnings.warn('Network returning invalid probability values. '\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##create the classifier\n",
    "## Instantiate the object and call the function\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "DATASET= \"MNIST\"\n",
    "IMG_DIM= 784\n",
    "IMG_HGT =28\n",
    "IMG_WDT=28\n",
    "IMG_DEPTH=1\n",
    "HIDDEN_LAYER_SIZE=196\n",
    "nClass=2\n",
    "MODEL_SAVE_PATH = PROJECT_DIR + \"/models/MNIST/OC_NN/\"\n",
    "REPORT_SAVE_PATH = PROJECT_DIR + \"/reports/figures/MNIST/OC_NN/\"\n",
    "PRE_TRAINED_WT_PATH = PROJECT_DIR +\"/models/MNIST/FF_NN/\"\n",
    "\n",
    "from src.models.OC_NN import OC_NN\n",
    "import keras\n",
    "\n",
    "ocnn = OC_NN(DATASET,IMG_DIM,HIDDEN_LAYER_SIZE,IMG_HGT,IMG_WDT,MODEL_SAVE_PATH,REPORT_SAVE_PATH,PRE_TRAINED_WT_PATH)\n",
    "\n",
    "\n",
    "nu= 0.01\n",
    "NUM_EPOCHS = 100\n",
    "ocnn.fit(trainX,nu,NUM_EPOCHS,IMG_HGT,IMG_WDT,IMG_DEPTH,nClass)\n",
    "res = ocnn.score(test_ones,test_sevens) \n",
    "auc_OCNN = res\n",
    "\n",
    "print(\"=\"*35)\n",
    "print(\"AUC:\",res)\n",
    "print(\"=\"*35)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing  AUC scores of various methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'AUC Comparision for MNIST Dataset ')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "auc = np.zeros((1,5))\n",
    "auc[0][0] = auc_FF_NN\n",
    "auc[0][1] = auc_FAKENOISE_FF_NN\n",
    "auc[0][2] = auc_OCSVM_linear\n",
    "auc[0][3] = auc_OCSVM_rbf\n",
    "auc[0][4] = auc_OCNN\n",
    "\n",
    "\n",
    "aucList = [auc_FF_NN,auc_FAKENOISE_FF_NN, auc_OCSVM_linear,auc_OCSVM_rbf, auc_OCNN]\n",
    "\n",
    "index = ['FF_NN', 'Fake_NN', 'OCSVM_L','OCSVM_rbf','OCNN']\n",
    "df = pd.DataFrame({'auc': aucList}, index=index)\n",
    "ax = df.plot.bar(rot=0)\n",
    "\n",
    "plt.ylabel('AUC')\n",
    "plt.xlabel('Methods')\n",
    "plt.title('AUC Comparision for MNIST Dataset ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
