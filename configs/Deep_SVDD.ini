[PLOT_PARAMETERS]
;directory for the experiment where log files should be written
xp_path: "../log/lhc/"

[EXPERIMENT]
; number of epochs
n_epochs: 50
; number of epochs before saving model
save_at:0
; Computation device to use for experiment
device: "cpu"
; xp_dir directory for the experiment
xp_dir: "../log/lhc/"
; name for inputs of experiment
in_name: "lhc_background_vs_signal"
; out_name name for inputs of experiment
out_name:  "lhc_background_vs_signal"
;["sgd", "momentum", "nesterov", "adagrad", "rmsprop", "adadelta", "adam", "adamax"])
solver: "adam"
;choices=["ce", "svdd", "autoencoder"]
loss: "svdd"
;
title_suffix:

[DATASET]
dataset:lhc
;seed: numpy seed default value=0
seed: 0
;out_frac: fraction of outliers in data set
out_frac:0
;ad_experiment: specify if experiment should be two- or multiclass by default it is ad: anomaly detection
ad_experiment: 1
;weight_dict_init: initialize first layer filters by dictionary
weight_dict_init:1

;apply pca in preprocessing
pca:0
;norm to use for scaling the data to unit norm type str "l2 or "l1"
unit_norm_used: l1
;apply global contrast normalization in preprocessing
gcn: 1
;specify if data should be zca whitened
zca_whitening:0

;=============================
; MNIST DATASET CONFIGS
;=============================
;specify the fraction the validation set of the initial training data should be default
mnist_val_frac:0.1
;specify if bias terms are used in MNIST network
mnist_bias:1
;specify the dimensionality of the last layer
mnist_rep_dim:16
;specify which network architecture should be used
mnist_architecture:1
;specify normal class in MNIST by default digit 1 is considered as normal
mnist_normal: 1
;specify outlier class in MNIST by default digit 7 is considered as outlier
mnist_outlier: 7


;=============================
; CIFAR-10 DATASET CONFIGS
;=============================
;specify if bias terms are used in CIFAR network
cifar10_bias:1
;specify the dimensionality of the last layer
cifar10_rep_dim:32
;specify which network architecture should be used
cifar10_architecture:1
;specify normal class in CIFAR-10 Dogs are considered normal and cats as anomalies
cifar10_normal: 3
;specify normal class in CIFAR-10 Dogs are considered normal and cats as anomalies
cifar10_outlier: 5

;=============================
; GTSRB DATASET CONFIGS
;=============================
;specify the dimensionality of the last layer
gtsrb_rep_dim:32


;=============================
; LHC DATASET CONFIGS
;=============================
;specify the fraction the validation set of the initial training data should be default
lhc_val_frac:0.1
;specify if bias terms are used in MNIST network
lhc_bias:1
;specify the dimensionality of the last layer
lhc_rep_dim:16
;specify which network architecture should be used
lhc_architecture:1
;specify normal class in LHC by default digit 1 is considered as normal
lhc_normal: 1
;specify outlier class in LHC by default digit 7 is considered as outlier ( signals are considered as outliers)
lhc_outlier: 0



[NETWORK_ARCHITECTURE]
;possible datasets to use ["mnist", "cifar10", "gtsrb","lhc"]
dataset: "lhc"
;solver the possible values are ["sgd", "momentum", "nesterov", "adagrad", "rmsprop", "adadelta", "adam", "adamax"]
solver:"adam"
;network possible loss functions loss function ["ce", "svdd", "autoencoder"]
softmax_loss: 'ce'
svdd_loss:'svdd'
reconstruction_loss: 'autoencoder'
;specify if Batch Normalization should be applied in the network default is zero
use_batch_norm:1
;initial learning rate
learning_rate:0.0001
;specify if the learning rate should be decayed
lr_decay:0

;specify the epoch after learning rate should decay
lr_decay_after_epoch:10
;specify if learning rate should drop in a specified epoch
lr_drop:1
;specify the epoch in which learning rate should drop default value is 50
lr_drop_in_epoch: 50
;specify the factor by which the learning rate should drop default value is 10
lr_drop_factor: 10
;momentum rate if optimization with momentum
momentum:0.9
;if using rmsprop the rho value
rmsprop_solver_rho:0.9
;if using adadelta_solver_rho value is 0.95
adadelta_solver_rho:0.95
;specify if radius R and center c (if c is not fixed) should be solved for via the dual
block_coordinate: 0
;update R and c in block coordinate descent only every k iterations default value is 0
k_update_epochs:0
;specify if center c should be fixed or not
center_fixed:1
;Solver for solving R ( minimum radius to be found) ["minimize_scalar", "lp"] by default use minimize_scalar
R_update_solver: "minimize_scalar"
; Optimization method if minimize_scalar for solving R ["brent", "bounded", "golden"]  default is "bounded"
R_update_scalar_method: "bounded"
;Objective used for searching R in a block coordinate descent via LP (primal or dual) choices=["primal", "dual"]
R_update_lp_obj: "primal"
;specify the first epoch the QP solver should be applied default value is 10
warm_up_n_epochs:10
;batch size default is 200
batch_size:200
;specify if ReLU layer should be leaky default value is 1
leaky_relu:1



[PRETRAIN_AUTOENCODER_CONFIG]
;specify if weights should be pre-trained via autoencoder 0 for no and 1 for yes
pretrain:1
; specify the reconstruction loss of the autoencoder default is l2
ae_loss: "l2"
;specify if learning rate should drop in a specified epoch
ae_lr_drop:0
; specify the epoch in which learning rate should drop default is 50
ae_lr_drop_in_epoch: 50
; specify the factor by which the learning rate should drop default is 10
ae_lr_drop_factor: 10
;specify if weight decay should be used in pretrain
ae_weight_decay:1
;regularization hyper-parameter in pretrain
ae_C:1e3


[SVDD_PARAMS]
;nu parameter in one-class SVM
nu:0.1
;specify if center c should be initialized as mean
c_mean_init:1
;from how many batches should the mean be computed? default -1 means all
c_mean_init_n_batches_value:-1
c_mean_init_n_batches_all:1
c_mean_init_n_batches: 0
;Train deep SVDD with hard-margin algorithm
hard_margin:0

[REGULARIZATION_PARAMS]
;specify if weight decay should be used default is 0
weight_decay:1

; regularization hyper-parameter
C:1e6
;specify if a reconstruction (autoencoder) penalty should be used
reconstruction_penalty:0
; reconstruction (autoencoder) penalty hyperparameter
C_rec:1e3
; specify specify if dropout layers should be applied
dropout:0
;specify if dropout architecture should be used
dropout_architecture:0

[DIAGNOSTICS]
;specify if diagnostics should be captured (faster training without)
nnet_diagnostics:1
; specify if diagnostics of first epoch per batch should be captured
e1_diagnostics:1
; specify if diagnostics should be captured in autoencoder (faster training without)
ae_diagnostics:1
























